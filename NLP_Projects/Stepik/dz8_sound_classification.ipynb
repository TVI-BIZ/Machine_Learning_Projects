{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_attempthomework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zahzrEdRCaxV"
      },
      "source": [
        "### Spoken Language Processing\n",
        "Homework 1\n",
        "1. Ссылка на занятие: https://www.twitch.tv/deeplearningschool\n",
        "2. Материалы: https://vk.cc/bVLCOC https://vk.cc/bVLD3Z\n",
        "\n",
        "В этом задании предлагается обучить классификатор класса возраста по голосу (пример с тем, как это можно сделать для пола см. в семинаре)\n",
        "\n",
        "P.S. не забудьте, что если то вы работает в Colab, то вы можете поменять среду выполнения на GPU/TPU!\n",
        "\n",
        "Вопросы по заданию/материалам: @Nestyme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wSgHrbiEc8x",
        "outputId": "5d54ce1f-ed6d-42b1-cc96-f1981ce4ffbc"
      },
      "source": [
        "!pip3 install timit-utils==0.9.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting timit-utils==0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/22/32/0c98f7f44386947b9e4080f54f09a7380c390e0b8337ab0b87050d49c43a/timit_utils-0.9.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from timit-utils==0.9.0) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from timit-utils==0.9.0) (1.19.4)\n",
            "Collecting SoundFile>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from timit-utils==0.9.0) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from timit-utils==0.9.0) (3.2.2)\n",
            "Collecting python-speech-features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->timit-utils==0.9.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->timit-utils==0.9.0) (2018.9)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from SoundFile>=0.8.0->timit-utils==0.9.0) (1.14.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->timit-utils==0.9.0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->timit-utils==0.9.0) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->timit-utils==0.9.0) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->timit-utils==0.9.0) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->SoundFile>=0.8.0->timit-utils==0.9.0) (2.20)\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5890 sha256=0e1666738d84e5160d476e30d999582f6386dae5b23f28b77921e42c85b08054\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: SoundFile, python-speech-features, timit-utils\n",
            "Successfully installed SoundFile-0.10.3.post1 python-speech-features-0.6 timit-utils-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PveQyMmsErXM",
        "outputId": "c967061c-57f0-424c-84e9-fe9c820f3b84"
      },
      "source": [
        "!pip3 install torchaudio"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/f9/618434cf4e46dc975871e1516f5499abef6564ab4366f9b2321ee536be14/torchaudio-0.7.2-cp36-cp36m-manylinux1_x86_64.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 15.0MB/s \n",
            "\u001b[?25hCollecting torch==1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/4f/acf48b3a18a8f9223c6616647f0a011a5713a985336088d7c76f3a211374/torch-1.7.1-cp36-cp36m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 23kB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1->torchaudio) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1->torchaudio) (1.19.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1->torchaudio) (3.7.4.3)\n",
            "\u001b[31mERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchaudio\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "Successfully installed torch-1.7.1 torchaudio-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifZp0NvTEo8V",
        "outputId": "d9937d9d-53c1-455e-847d-3064c76c6a91"
      },
      "source": [
        "! wget https://ndownloader.figshare.com/files/10256148 "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-26 19:27:41--  https://ndownloader.figshare.com/files/10256148\n",
            "Resolving ndownloader.figshare.com (ndownloader.figshare.com)... 52.50.75.128, 52.19.63.8, 52.208.145.173, ...\n",
            "Connecting to ndownloader.figshare.com (ndownloader.figshare.com)|52.50.75.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10256148/TIMIT.zip [following]\n",
            "--2020-12-26 19:27:42--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10256148/TIMIT.zip\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.84.106\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.84.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 440207227 (420M) [binary/octet-stream]\n",
            "Saving to: ‘10256148’\n",
            "\n",
            "10256148            100%[===================>] 419.81M  34.7MB/s    in 13s     \n",
            "\n",
            "2020-12-26 19:27:55 (33.0 MB/s) - ‘10256148’ saved [440207227/440207227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W401P4FhEq0c"
      },
      "source": [
        "!unzip -q 10256148"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0bovLZ0Ew5V"
      },
      "source": [
        "import timit_utils as tu\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import IPython\n",
        "_TIMIT_PATH = 'data/lisa/data/timit/raw/TIMIT'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd-qfC9-DdnJ"
      },
      "source": [
        "## Задание 1\n",
        "Загрузите данные для обучения. Для этого:\n",
        "1. Скачайте датасет TIMIT (см семинар)\n",
        "2. Соберите пары \"голос\"  — \"класс возраста\" также, как на семинаре собирались пары \"голос\"  — \"пол\". Аудиодорожки сконвертируйте в мелспектрограммы при помощи `torchaudio либо` `librosa`\n",
        "\n",
        "P.S. вы можете использовать свою реализацию, а можете предложенную (см следующие ячейки)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkd8_BRD3RNy"
      },
      "source": [
        "%matplotlib inline\n",
        "import timit_utils as tu\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch as t\n",
        "import timit_utils.audio_utils as au\n",
        "import timit_utils.drawing_utils as du\n",
        "from datetime import datetime, date\n",
        "\n",
        "DATA_PATH = 'data/lisa/data/timit/raw/TIMIT'\n",
        "corpus = tu.Corpus(DATA_PATH)\n",
        "sentence = corpus.train.sentences_by_phone_df('aa').sentence[0]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN9q-lw0AQvE"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyvIgt1H5Tiw"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdbF2Zbs7Xsf"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhPyP4T5DdAD"
      },
      "source": [
        "\n",
        "class timit_dataloader:\n",
        "    def __init__(self, data_path=_TIMIT_PATH, train_mode=True, age_mode=True):\n",
        "        self.doc_file_path = os.path.join(data_path, 'DOC', 'SPKRINFO.TXT')\n",
        "        self.corpus = tu.Corpus(data_path)\n",
        "        with open(self.doc_file_path) as f:\n",
        "            self.id_age_dict = dict(\n",
        "                [(tmp.split(' ')[0], 86 - int(tmp.split('  ')[5].split('/')[-1].replace('??', '50'))) \\\n",
        "                 for tmp in f.readlines()[39:]])\n",
        "        if train_mode:\n",
        "            self.trainset = self.create_dataset('train', age_mode=age_mode)\n",
        "            self.validset = self.create_dataset('valid', age_mode=age_mode)\n",
        "        self.testset = self.create_dataset('test', age_mode=age_mode)\n",
        "\n",
        "    def return_age(self, id):\n",
        "        return self.id_age_dict[id]\n",
        "\n",
        "    def return_data(self):\n",
        "        return self.trainset, self.validset, self.testset\n",
        "\n",
        "    def return_test(self):\n",
        "        return self.testset\n",
        "\n",
        "    def create_dataset(self, mode, age_mode=False):\n",
        "        global people\n",
        "        assert mode in ['train', 'valid', 'test']\n",
        "        if mode == 'train':\n",
        "            people = [self.corpus.train.person_by_index(i) for i in range(350)]\n",
        "        if mode == 'valid':\n",
        "            people = [self.corpus.train.person_by_index(i) for i in range(350, 400)]\n",
        "        if mode == 'test':\n",
        "            people = [self.corpus.test.person_by_index(i) for i in range(150)]\n",
        "        spectrograms_and_targets = []\n",
        "        for person in tqdm(people):\n",
        "              try:\n",
        "                  target = self.return_age(person.name)\n",
        "                  #print(target,'Return_Age')\n",
        "                  for i in range(len(person.sentences)):\n",
        "                      spectrograms_and_targets.append(\n",
        "                          self.preprocess_sample(person.sentence_by_index(i).raw_audio, target, age_mode=True))\n",
        "              except:\n",
        "                  print(person.name, target)\n",
        "\n",
        "        X, y = map(np.stack, zip(*spectrograms_and_targets))\n",
        "        X = X.transpose([0, 2, 1])  # to [batch, time, channels]\n",
        "        #print(y,'Y') # None detected!\n",
        "        return X, y\n",
        "\n",
        "    @staticmethod\n",
        "    def spec_to_image(spec, eps=1e-6):\n",
        "        mean = spec.mean()\n",
        "        std = spec.std()\n",
        "        spec_norm = (spec - mean) / (std + eps)\n",
        "        spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
        "        spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
        "        spec_scaled = spec_scaled.astype(np.uint8)\n",
        "        return spec_scaled\n",
        "\n",
        "    @staticmethod\n",
        "    def clasterize_by_age(age):\n",
        "        if age <= 25:\n",
        "            return 0.0\n",
        "        elif 25 < age <= 40:\n",
        "            return 0.5\n",
        "        elif age > 40:\n",
        "            return 1.0\n",
        "        else:\n",
        "            print(age,'Age!')\n",
        "            return 1\n",
        "\n",
        "    def preprocess_sample(self, amplitudes, target, age_mode=False, sr=16000, max_length=150):\n",
        "        spectrogram = librosa.feature.melspectrogram(amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
        "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
        "        target = self.clasterize_by_age(target)\n",
        "        #print(target,'Clasterise')\n",
        "        return self.spec_to_image(np.float32(spectrogram)), target\n",
        "\n",
        "    def preprocess_sample_inference(self, amplitudes, sr=16000, max_length=150, device='cpu'):\n",
        "        spectrogram = librosa.feature.melspectrogram(amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
        "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
        "        spectrogram = np.array([self.spec_to_image(np.float32(spectrogram))]).transpose([0, 2, 1])\n",
        "\n",
        "        return t.tensor(spectrogram, dtype=t.float).to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class dataloader:\n",
        "    def __init__(self, spectrograms, targets):\n",
        "        self.data = list(zip(spectrograms, targets))\n",
        "\n",
        "    def next_batch(self, batch_size, device):\n",
        "        indices = np.random.randint(len(self.data), size=batch_size)\n",
        "\n",
        "        input = [self.data[i] for i in indices]\n",
        "        #print(input)\n",
        "\n",
        "        source = [line[0] for line in input]\n",
        "        target = [line[1] for line in input]\n",
        "\n",
        "        return self.torch_batch(source, target, device)\n",
        "\n",
        "    @staticmethod\n",
        "    def torch_batch(source, target, device):\n",
        "        #print(target)\n",
        "        return tuple(\n",
        "            [\n",
        "                t.tensor(val, dtype=t.float).to(device, non_blocking=True)\n",
        "                for val in [source, target]\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def padd_sequences(lines, pad_token=0):\n",
        "        lengths = [len(line) for line in lines]\n",
        "        max_length = max(lengths)\n",
        "\n",
        "        return np.array(\n",
        "            [\n",
        "                line + [pad_token] * (max_length - lengths[i])\n",
        "                for i, line in enumerate(lines)\n",
        "            ]\n",
        "        )"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpz1Q5VOFxLM"
      },
      "source": [
        "Простая сверточная сеть, ее можно дотюнить или поменять по желанию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF9fIVq7Dbwx"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, window_sizes=(3, 4, 5)):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n",
        "            for window_size in window_sizes\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(128 * len(window_sizes), 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply a convolution + max pool layer for each window size\n",
        "        x = torch.unsqueeze(x, 1)  # [B, C, T, E] Add a channel dim.\n",
        "        xs = []\n",
        "        for conv in self.convs:\n",
        "            x2 = F.relu(conv(x))  # [B, F, T, 1]\n",
        "            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n",
        "            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n",
        "            xs.append(x2)\n",
        "        x = torch.cat(xs, 2)  # [B, F, window]\n",
        "\n",
        "        # FC\n",
        "        x = x.view(x.size(0), -1)  # [B, F * window]\n",
        "        logits = self.fc(x)  # [B, class]\n",
        "        probs = torch.sigmoid(logits).view(-1)\n",
        "        return probs\n",
        "\n",
        "    def loss(self, probs, targets):\n",
        "        return nn.BCELoss()(probs.float(), targets.float())"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EoOR641Fkzx",
        "outputId": "7fe33c2b-19c7-4de4-c36a-cde059acc356"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'using {device} mode')\n",
        "patience = 500\n",
        "best_loss = 1000\n",
        "cnt = 0\n",
        "\n",
        "model = Model()\n",
        "if device == torch.device('cuda'):\n",
        "    model.cuda()\n",
        "else:\n",
        "    model.cpu()\n",
        "model.train()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cpu mode\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 128, kernel_size=[3, 128], stride=(1, 1), padding=(2, 0))\n",
              "    (1): Conv2d(1, 128, kernel_size=[4, 128], stride=(1, 1), padding=(3, 0))\n",
              "    (2): Conv2d(1, 128, kernel_size=[5, 128], stride=(1, 1), padding=(4, 0))\n",
              "  )\n",
              "  (fc): Linear(in_features=384, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLUggB9iF6s_",
        "outputId": "2c7ebd8b-c712-4b29-bf9f-f55f3e80d943"
      },
      "source": [
        "_timit_dataloader = timit_dataloader()\n",
        "train, valid, test = _timit_dataloader.return_data()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 350/350 [00:42<00:00,  8.29it/s]\n",
            "100%|██████████| 50/50 [00:06<00:00,  8.09it/s]\n",
            "100%|██████████| 150/150 [00:19<00:00,  7.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJSCJtjATIX4"
      },
      "source": [
        "trainset = dataloader(*train)\n",
        "validset = dataloader(*valid)\n",
        "testset = dataloader(*test)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "optimizer = Adam(\n",
        "    [p for p in model.parameters() if p.requires_grad], betas=(0.9, 0.999), eps=1e-5\n",
        ")"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxViJnJ1Tvdx"
      },
      "source": [
        "#trainset.next_batch(64,device=device)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM_P6vFtP7N_",
        "outputId": "7c28d96c-d7e6-46c2-e497-2fe48f60bc6f"
      },
      "source": [
        "import torch as t\n",
        "for i in tqdm(range(100)):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    input, target = trainset.next_batch(BATCH_SIZE, device=device)\n",
        "    out = model(input)\n",
        "    loss = model.loss(out, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            input, target = validset.next_batch(BATCH_SIZE, device=device)\n",
        "            out = model(input)\n",
        "            valid_loss = model.loss(out, target)\n",
        "            out, target = out.cpu().detach().numpy(), target.cpu().detach().numpy()\n",
        "            # print(out, target)\n",
        "            out = [1. if tmp > 0.5 else 0.0 for tmp in out]\n",
        "            #print(out,'Out')\n",
        "            #print(target,'target')\n",
        "            print(f'accuracy_score:{accuracy_score(out, target.round())}')\n",
        "            print(\"i {}, valid {}\".format(i, valid_loss.item()))\n",
        "            print(\"_________\")\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    if i % 50 == 0 and best_loss > valid_loss.item():\n",
        "        best_loss = valid_loss.item()\n",
        "        cnt = 0\n",
        "    else:\n",
        "        cnt += 1\n",
        "\n",
        "    if cnt > patience:\n",
        "        break\n",
        "print('training finished')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 1/100 [00:00<01:10,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy_score:0.09375\n",
            "i 0, valid 3.1591479778289795\n",
            "_________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 51%|█████     | 51/100 [00:22<00:25,  1.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy_score:0.640625\n",
            "i 50, valid 0.9619367122650146\n",
            "_________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:44<00:00,  2.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScCZEMvXHkmz"
      },
      "source": [
        "#Задание 2\n",
        "1. Обучите свой классификатор категории возраста\n",
        "2. Попробуйте улучшить результат. Можно попробовать усложнить сетку, подвигать границы категорий, поискать новые данные, что угодно, кроме учиться на тесте :)\n",
        "3. Какой подход оказался самым эффективным? Как думаете, почему?\n",
        "4. Как считаете, где можно было бы применить такой классификатор в качестве вспомогательной задачи?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ts_JAhkmac6"
      },
      "source": [
        "class timit_dataloader:\n",
        "    def __init__(self, data_path=_TIMIT_PATH, train_mode=True, age_mode=True):\n",
        "        self.doc_file_path = os.path.join(data_path, 'DOC', 'SPKRINFO.TXT')\n",
        "        self.corpus = tu.Corpus(data_path)\n",
        "        with open(self.doc_file_path) as f:\n",
        "            self.id_age_dict = dict(\n",
        "                [(tmp.split(' ')[0], 86 - int(tmp.split('  ')[5].split('/')[-1].replace('??', '50'))) \\\n",
        "                 for tmp in f.readlines()[39:]])\n",
        "        if train_mode:\n",
        "            self.trainset = self.create_dataset('train', age_mode=age_mode)\n",
        "            self.validset = self.create_dataset('valid', age_mode=age_mode)\n",
        "        self.testset = self.create_dataset('test', age_mode=age_mode)\n",
        "\n",
        "    def return_age(self, id):\n",
        "        return self.id_age_dict[id]\n",
        "\n",
        "    def return_data(self):\n",
        "        return self.trainset, self.validset, self.testset\n",
        "\n",
        "    def return_test(self):\n",
        "        return self.testset\n",
        "\n",
        "    def create_dataset(self, mode, age_mode=False):\n",
        "        global people\n",
        "        assert mode in ['train', 'valid', 'test']\n",
        "        if mode == 'train':\n",
        "            people = [self.corpus.train.person_by_index(i) for i in range(350)]\n",
        "        if mode == 'valid':\n",
        "            people = [self.corpus.train.person_by_index(i) for i in range(350, 400)]\n",
        "        if mode == 'test':\n",
        "            people = [self.corpus.test.person_by_index(i) for i in range(150)]\n",
        "        spectrograms_and_targets = []\n",
        "        for person in tqdm(people):\n",
        "              try:\n",
        "                  target = self.return_age(person.name)\n",
        "                  #print(target,'Return_Age')\n",
        "                  for i in range(len(person.sentences)):\n",
        "                      spectrograms_and_targets.append(\n",
        "                          self.preprocess_sample(person.sentence_by_index(i).raw_audio, target, age_mode=True))\n",
        "              except:\n",
        "                  print(person.name, target)\n",
        "\n",
        "        X, y = map(np.stack, zip(*spectrograms_and_targets))\n",
        "        X = X.transpose([0, 2, 1])  # to [batch, time, channels]\n",
        "        #print(y,'Y') # None detected!\n",
        "        return X, y\n",
        "\n",
        "    @staticmethod\n",
        "    def spec_to_image(spec, eps=1e-6):\n",
        "        mean = spec.mean()\n",
        "        std = spec.std()\n",
        "        spec_norm = (spec - mean) / (std + eps)\n",
        "        spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
        "        spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
        "        spec_scaled = spec_scaled.astype(np.uint8)\n",
        "        return spec_scaled\n",
        "\n",
        "    @staticmethod\n",
        "    def clasterize_by_age(age):\n",
        "        if age <= 25:\n",
        "            return 0\n",
        "        elif 25 < age <= 40:\n",
        "            return 1\n",
        "        elif age > 40:\n",
        "            return 2\n",
        "        else:\n",
        "            print(age,'Age!')\n",
        "            return 2\n",
        "\n",
        "    def preprocess_sample(self, amplitudes, target, age_mode=False, sr=16000, max_length=150):\n",
        "        spectrogram = librosa.feature.melspectrogram(amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
        "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
        "        target = self.clasterize_by_age(target)\n",
        "        #print(target,'Clasterise')\n",
        "        return self.spec_to_image(np.float32(spectrogram)), target\n",
        "\n",
        "    def preprocess_sample_inference(self, amplitudes, sr=16000, max_length=150, device='cpu'):\n",
        "        spectrogram = librosa.feature.melspectrogram(amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
        "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
        "        spectrogram = np.array([self.spec_to_image(np.float32(spectrogram))]).transpose([0, 2, 1])\n",
        "\n",
        "        return t.tensor(spectrogram, dtype=t.float).to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class dataloader:\n",
        "    def __init__(self, spectrograms, targets):\n",
        "        self.data = list(zip(spectrograms, targets))\n",
        "\n",
        "    def next_batch(self, batch_size, device):\n",
        "        indices = np.random.randint(len(self.data), size=batch_size)\n",
        "\n",
        "        input = [self.data[i] for i in indices]\n",
        "        #print(input)\n",
        "\n",
        "        source = [line[0] for line in input]\n",
        "        target = [line[1] for line in input]\n",
        "\n",
        "        return self.torch_batch(source, target, device)\n",
        "\n",
        "    @staticmethod\n",
        "    def torch_batch(source, target, device):\n",
        "        #print(target)\n",
        "        return tuple(\n",
        "            [\n",
        "                t.tensor(val, dtype=t.float).to(device, non_blocking=True)\n",
        "                for val in [source, target]\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def padd_sequences(lines, pad_token=0):\n",
        "        lengths = [len(line) for line in lines]\n",
        "        max_length = max(lengths)\n",
        "\n",
        "        return np.array(\n",
        "            [\n",
        "                line + [pad_token] * (max_length - lengths[i])\n",
        "                for i, line in enumerate(lines)\n",
        "            ]\n",
        "        )"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GE-E3EHmafd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, window_sizes=(3, 4, 5)):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n",
        "            for window_size in window_sizes\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(128 * len(window_sizes), 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply a convolution + max pool layer for each window size\n",
        "        x = torch.unsqueeze(x, 1)  # [B, C, T, E] Add a channel dim.\n",
        "        xs = []\n",
        "        for conv in self.convs:\n",
        "            x2 = F.relu(conv(x))  # [B, F, T, 1]\n",
        "            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n",
        "            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n",
        "            xs.append(x2)\n",
        "        x = torch.cat(xs, 2)  # [B, F, window]\n",
        "\n",
        "        # FC\n",
        "        x = x.view(x.size(0), -1)  # [B, F * window]\n",
        "        logits = self.fc(x)  # [B, class]\n",
        "        #probs = torch.sigmoid(logits).view(-1)\n",
        "        probs = torch.softmax(logits,dim=1)\n",
        "        return probs\n",
        "\n",
        "    def loss(self, probs, targets):\n",
        "        #return nn.BCELoss()(probs.float(), targets.float())\n",
        "        tr_long = targets.long()\n",
        "        return nn.CrossEntropyLoss()(probs.float(), tr_long)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW7tDxBLmaiV",
        "outputId": "4f6ecb11-ff8d-4bf7-e6a9-cac8cf890912"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'using {device} mode')\n",
        "patience = 500\n",
        "best_loss = 1000\n",
        "cnt = 0\n",
        "\n",
        "model = Model()\n",
        "if device == torch.device('cuda'):\n",
        "    model.cuda()\n",
        "else:\n",
        "    model.cpu()\n",
        "model.train()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cpu mode\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 128, kernel_size=[3, 128], stride=(1, 1), padding=(2, 0))\n",
              "    (1): Conv2d(1, 128, kernel_size=[4, 128], stride=(1, 1), padding=(3, 0))\n",
              "    (2): Conv2d(1, 128, kernel_size=[5, 128], stride=(1, 1), padding=(4, 0))\n",
              "  )\n",
              "  (fc): Linear(in_features=384, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIynnPN5makt",
        "outputId": "c321fe24-c281-44d3-ec61-50d214f9bb5f"
      },
      "source": [
        "_timit_dataloader = timit_dataloader()\n",
        "train, valid, test = _timit_dataloader.return_data()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 350/350 [00:41<00:00,  8.33it/s]\n",
            "100%|██████████| 50/50 [00:06<00:00,  8.18it/s]\n",
            "100%|██████████| 150/150 [00:18<00:00,  7.98it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSnYo-mGman0"
      },
      "source": [
        "trainset = dataloader(*train)\n",
        "validset = dataloader(*valid)\n",
        "testset = dataloader(*test)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "optimizer = Adam(\n",
        "    [p for p in model.parameters() if p.requires_grad], betas=(0.9, 0.999), eps=1e-5\n",
        ")"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sfOjGnal5Iu",
        "outputId": "ab7bbd8e-6fae-47bf-a07f-a96adb53128d"
      },
      "source": [
        "import torch as t\n",
        "for i in tqdm(range(100)):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    input, target = trainset.next_batch(BATCH_SIZE, device=device)\n",
        "    out = model(input)\n",
        "    loss = model.loss(out, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            input, target = validset.next_batch(BATCH_SIZE, device=device)\n",
        "            out = model(input)\n",
        "            valid_loss = model.loss(out, target)\n",
        "            out, target = out.cpu().detach().numpy(), target.cpu().detach().numpy()\n",
        "            out = torch.argmax(torch.tensor(out),1)\n",
        "            #print(out,'Out')\n",
        "            print(target,'target')\n",
        "            print(f'accuracy_score:{accuracy_score(out, target)}')\n",
        "            print(\"i {}, valid {}\".format(i, valid_loss.item()))\n",
        "            print(\"_________\")\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    if i % 50 == 0 and best_loss > valid_loss.item():\n",
        "        best_loss = valid_loss.item()\n",
        "        cnt = 0\n",
        "    else:\n",
        "        cnt += 1\n",
        "\n",
        "    if cnt > patience:\n",
        "        break\n",
        "print('training finished')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 1/100 [00:00<01:10,  1.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 2. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 2. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 2. 2. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1.] target\n",
            "accuracy_score:0.640625\n",
            "i 0, valid 0.910712480545044\n",
            "_________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 51%|█████     | 51/100 [00:23<00:25,  1.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1. 0. 1. 0. 2. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 2. 0.\n",
            " 2. 0. 0. 1. 1. 1. 1. 0. 1. 2. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 2. 0.] target\n",
            "accuracy_score:0.640625\n",
            "i 50, valid 0.910819947719574\n",
            "_________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:45<00:00,  2.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLPPBLy1nYpa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1A7B9NAvQnJ"
      },
      "source": [
        "Самый больший эффект дало сдвиг возрастов.Более молодых до 20 лет, от 20 до 50 и старше 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Z8kZKPvcWk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}